---
title: "Capital One Data challenge"
author: "Alex Kiiru"
date: "January 22, 2021"
output:
  html_document:
    df_print: paged
    theme: united
    toc: yes
  word_document:
    toc: yes
  pdf_document:
    toc: yes
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,fig.width = 10,warning = FALSE,message = FALSE)
options(scipen=99999)
```
# Executive Summary

The Airbnb and Zillow datases provides us with a fantastic source of data to better understand New York’s rental landscape. With over 50k listings registered in the last 9 years, New York has proven to be one of Airbnb’s fastest growing cities. Between 2010 and 2017, as more and more people adopted the use of the internet as a service provider, the number of listings doubled every year. From our analysis, downtown Manhattan and the adjacent parts of Brooklyn had the highest concentration of listings by far. Staten Island and Bronx were the slow adopters but the data showed an increasing trend. 

## Problem Statement
You are consulting for a real estate company that has a niche in purchasing properties to rent out short-term as part of their business model specifically within New York City. The real estate company has already concluded that two bedroom properties are the most profitable; however, they do not know which zip codes are the best to invest in.

## Objective
The task  given is to analyse the datasets of Airbnb and Zillow to answer the following question:

+ Which zip codes are the most profitable to invest in within New York City for two bed room properties

## Assumptions

+ The investor will pay for the property in cash (i.e. no mortgage/interest rate will need to be accounted for).
+ The time value of money discount rate is 0% (i.e. $1 today is worth the same 100 years from now).
+ All properties and all square feet within each locale can be assumed to be homogeneous (i.e. a 1000 square foot property in a   locale such as Bronx or Manhattan generates twice the revenue and costs twice as much as any other 500 square foot property within that same locale.)
+ The Occupancy Rate has been derived on the basis of certain conditions relating to Neighborhood and Overall Ratings (will be further discussed in the Analysis)
+ Imputation has been done on the basis of the MICE package in R. The package creates multiple imputations (replacement values) for multivariate missing data.
+ We now know that Covid-19 is a factor that would be have to be accounted for in order to make accurate predictions for investors in 2021, but this factor is omitted from this analysis because it is based only on data from 1996-2017. 

 

## Key Insights 
+ Renters in the neighbourhoods of Staten Island and Queens have limited choices because there are fewer properties listed there, but these are desirable neighborhoods for investors because they cost less, are highly popular rentals, and return higher rental prices.
+ Properties in Manhattan and Brookly have seen major property price increase in the last 5-10 years and thus could have high resale value. Property prices in Staten Island and Queens have been stagnant for over a decade.

## Results 
Using different approaches discussed in the model building segment of this report, the best zipcodes to invest in are: 

1. Optimal Revenue Model: 11231 ,11217 ,11215, 10036,10025 ,10003 ,10011 ,10128

2. Break Even Model: 11434,10304,10309, 11234

3. Mean Return Rate Model: 11434, 11234, 11304

These zipcodes derive higher daily rental value, provide more choices, and are popular among current consumers in terms of number of reviews and occupancy.

## Future steps & Recommedations
+ Expand this analysis to multiple cities with compare patterns and trends between different cities. From the insights that have been derived, I would also like to build predictive models using different features from the dataset.

+ Merge this data with Covid-19 data to see how the pandemic would affect the demand and supply of airbnb rentals in the next few years in New York.

+ Introduce seasonality and weather data to understand trends in occupancy rates throughout the year and create a model to predict occupancy rate based on this insight.

+ Use NLP models to analyze the qualitative part of Airbnab data. We can account for the trends in reviews and get sentimental insights from word cloud that drive demand and occupancy rates.

# Metadata Created
+ Annual_Return_rate - revenue generated by property per year dived by predicted price of the property 
+ mean_Return_Rate - mean revenue genarated by property per year
+ predicted_price - predicted cost price from the zillow data set. In the data set only the price as of february 2021 2019 is taken and is in dollar amount
+ occupancy_rate - Percentage occupancy of the airbnb listing. It is represented as intervals.
+ breakeven_period - Time it takes for the property to return it’s cost price. This is also known as breakeven period and it is taken in the form of years
+ Annual_return - revenue generated by property per year

# Package Loading

Required Packages

+ Tidyverse (dplyr, ggplot2..) - Data Read, Manipulation and visualisation
+ Data Explorer - EDA & Generate Reports
+ Caret - Pre Processing, Feature Selection
+ Plotly - Interactive Visualization
+ KableExtra - Styling  Data Tables within Markdown
+ MatrixStats - for manipulating operating on rows and columns of matrices.
+ Choropleth packages -for spatial data 
+ Ggmap- for spatial data 
+ Other minor packages described in config file.

```{r}
###loading required packages 
library(tidyverse)
library(tidyr)
library(readr)    
library(GGally)   
library(DT)       
library(leaflet)  
library(glue)
library(matrixStats)
library(ggplot2)
library(sqldf)
library(kableExtra)
library(prophet)
library(ggmap)
library(forcats)
library(mice)
library(DataExplorer)
library(choroplethr)
library(choroplethrMaps)
library(choroplethrZip)
library(plotly)

```

# Loading Data into R Environment
Revenue(Airbnb_data) and Cost(Zillow) Datasets are loaded into R-Enviroment for Exploratory data analysis. If new markets or cities have to be explored at a later stage, new files must be loaded into the same directory and the code will automatically scale to account for it.

## Loading Airbnb_data Data

```{r,echo=TRUE,message=FALSE,warning=FALSE}
Airbnb_data <- read.csv("C:/Users/kiiru/Desktop/Cpaital_one _data_challege/listings.csv")

```

## Loading Zillow  Data 

```{r,echo=TRUE,message=FALSE,warning=FALSE}
Zillow_data <- read.csv("C:/Users/kiiru/Desktop/Cpaital_one _data_challege/Zip_Zhvi_2bedroom_2021.csv",check.names= FALSE,fileEncoding = "UTF-8-BOM")
```

## Dimension and Shape Analysis of Zillow and Airbnb_data data
Checking Dimension of both data sets (Number of Rows, Number of Columns)

```{r dimension analysis}
dim(Airbnb_data )
dim(Zillow_data)

```
### Data Structure 

We check the data structuctures and variable names in each data set.
```{r}

## column names
#names(Zillow_data)

## column names
#names(Airbnb_data)

## structure of Zillow_data
#str(Zillow_data)

## structure of Zillow_data
#str(Airbnb_data)

```
# Initial Data Preprocessing

## Data Preparation Zillow data set

In the Zillow dataset below, most of the columns represent median prices for 2-bedroom homes between 1996 to 2017 with one month spread.

```{r}
#quick view of Zillow data set 
 kable(head(Zillow_data))  %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>%     scroll_box(width = "100%", height = "300px")
```

### Quality Check of Zillow data 

#### Missing value Check

Median Price for early years (1996-2013) has many Nulls as shown in the table below. This is not consistent across all region names. Steps are taken in the following section to filter columns with higher percentage of Nulls/NA.

```{r}
total_missing_values <-sapply(Zillow_data, function(x) sum(length(which(is.na(x)))))

kable(as.data.frame(total_missing_values)) %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "250px")
```

#### Duplicates values check

We can see that our data does not have duplicates. 

```{r}
Zillow_data[which(duplicated(Zillow_data) ==T),] 

```

```{r}
length(unique(Zillow_data$RegionID)) == length(Zillow_data$RegionID)
```

```{r}
length(unique(Zillow_data$RegionName)) == length(Zillow_data$RegionName)
```
#### Negative and Zero valued columns check

There are no negative or zero Values in any of the non-character columns(Int/Numeric) as shown in the following table.

```{r}
zillow_Char_Col <- colnames(Zillow_data %>% ungroup() %>% select_if(is.character))

zillow_neg_and_zero <-
  sapply(Zillow_data[, !(names(Zillow_data) %in% zillow_Char_Col)], function(x)
  count(x <= 0, na.rm = TRUE))
kable(as.data.frame(zillow_neg_and_zero)) %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "80%", height = "300px")
```


### Filtering Data to get Desired Region (New york)

To reduce the number of columns and only focus on our desired region, the Zillow data is filtered to only show New York region. In the future, if a different city is desired, the name of the city can be changed to the desired city.

```{r, echo=FALSE,message=FALSE,warning=FALSE}
#Filtering for new york City
desired_region = "New York"

zillow_nyc<-Zillow_data %>% filter(City==desired_region) %>%
select(-c(RegionID,City,State,Metro,CountyName,SizeRank))
colnames(zillow_nyc)[1]<-"zipcode"
trans_zil = setNames(data.frame(t(zillow_nyc[,-1])), zillow_nyc[,1])
present<-data.frame(ds=seq.Date(from = as.Date('1996/04/01'),to = as.Date('2017/06/01'),by = 'month'))
```

```{r ,echo=FALSE,message=FALSE,warning=FALSE}
### glimpse of the filtered data 
kable(head(zillow_nyc))  %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "350px")
```
### Predicting prices for houses untill 2021
Used Facebook open source Prophet package to identify and extrapolate the trends in house prices in New York.
```{r}
# Predicting prices till February 2021
future<-data.frame(ds=seq.Date(from = as.Date('1996/04/01'),to = as.Date('2021/02/01'),by = 'month'))
bind_for_prophet<-apply(trans_zil,2,cbind.data.frame,present)
bind_for_prophet<-lapply(bind_for_prophet, setNames,c('y','ds'))
make_model<-lapply(bind_for_prophet, prophet,daily.seasonality=TRUE,weekly.seasonality=TRUE)
forecast<-lapply(make_model, predict,future)
extract_yhat<-lapply(forecast, function(x) x[, 'yhat'][nrow(future)])
```

```{r}
# Set predicted price in original data frame 
zillow_nyc$predicted_price<-unlist(extract_yhat)
head(zillow_nyc)
```

### Visualizing predicted price
Randomly picked a zip code (11231) to demonstrate the results generated by the model. The model predicts an increase in housing prices to around $1.6 million by 2021.

```{r dyplots}
#using the model to predict price for zipciode 11231 
dyplot.prophet(make_model$`11231`,forecast$`11231`)
```

### Visualizing Housing Price prediction from 1996-2021 in New York
This graph shows the predicted price for February 2021, for each of the zip codes.

```{r}
library(RColorBrewer)
## barplot Housing Price prediction from 1996-2021 in Newyork
par(las=2)
par(mar=c(5,8,4,2)+0.1)
coul <- brewer.pal(25, "Set2")
barplot(height=zillow_nyc$predicted_price, names=zillow_nyc$zipcode,col=coul, xlab="Zipcodes", 
         main="Housing Price prediction from 1996-2021 in Newyork",cex.names = 0.65)

```

### Filtering final data for merging
```{r}
# desired  columns from zillow data 
cols<-c('zipcode','2017-06','predicted_price')
zillow_nyc_final<-zillow_nyc[,cols]
zillow_nyc_final$zipcode<-as.factor(zillow_nyc_final$zipcode)
```

```{r}
#### head of the selected data 
kable(tail(zillow_nyc_final))  %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "350px")
```


## Data Preparation Airbnb_data data set

Revenue data contains a mix of information including details about the properties, like address, zip code, bedrooms, bathrooms, information about host, daily/weekly and monthly price details for stays.

```{r}
kable(head(Airbnb_data))  %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "250px")
```
### Quality Check of Airbnb_data

#### Missing value Check

The data Airbnb also had null values. To preserve all the information, we will impute or drop the rows and columns containing null values later on in this project, while conducting exploratory analysis that makes use of these features.

```{r}
# checking missing values in Airbnb_data
total_missing_values <-sapply(Airbnb_data, function(x) sum(length(which(is.na(x)))))  
kable(as.data.frame(total_missing_values)) %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "250px")
```
We construct a Histogram  plot to analyze the missing values for the variables that we use in our exploratory analysis

```{r}
## hist of missing values 
hist(total_missing_values,col="chocolate" )
```


#### Duplicates values check

There were no duplicates found in the Airbnb data.

```{r}
### checking for duplicates 
Airbnb_data[which(duplicated(Airbnb_data) ==T),] 
```
#### Negative and Zero valued columns check

There were no negative or zero valued columns  found in the Airbnb data.

```{r}

Airbnb_data_Char_Col <- colnames(Airbnb_data %>% ungroup() %>% select_if(is.character))


Airbnb_data_neg_Zero_count <-sapply(Airbnb_data[,!(names(Airbnb_data) %in% Airbnb_data_Char_Col)], function(x)
  count(x <= 0, na.rm = TRUE))
kable(as.data.frame(Airbnb_data_neg_Zero_count)) %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "350px")
```

### Checking columns with no data


```{r}
filterNA<-function(column)
  {
  
  if(sum(is.na(column))>0)
  {
    sum(is.na(column))
  }
}

how_many_NA<-data.frame('missing values'=sort(unlist(apply(Airbnb_data, 2, filterNA)),decreasing = T))
kable(x = how_many_NA ,caption = "Missing value analysis")
```


```{r}
Airbnb_data <-
  Airbnb_data %>% group_by(neighbourhood_group_cleansed) %>% fill(zipcode) %>% ungroup()

sum(is.array(Airbnb_data$zipcode))
```
### Zip code data integrity 
48,372 zip codes had the correct length, whereas 523 zip codes had incorrect lengths.
```{r zipcode_integrity}
kable(x=sum(str_count(Airbnb_data$zipcode,pattern = "[0-9]")==5),caption = "zipcodes with correct length",col.names = 'zipcode',align='l')
kable(x=nrow(Airbnb_data)-sum(str_count(Airbnb_data$zipcode,pattern = "[0-9]")==5),caption="zipcodes with incorrect length",col.names = 'zipcode',align = 'l')

```
### Filtering final data for merging
```{r}
Airbnb_data_final <- select(Airbnb_data, id, host_id, street, neighbourhood, neighbourhood_cleansed, neighbourhood_group_cleansed,   city,   zipcode,    market, smart_location, latitude,   longitude, accommodates, bathrooms, bedrooms, beds, price, weekly_price, monthly_price, security_deposit,  cleaning_fee, review_scores_location,review_scores_value,  guests_included, extra_people, availability_30, availability_60, availability_90, availability_365, cancellation_policy,room_type )
head(Airbnb_data_final)

```

```{r}
dim(Airbnb_data_final)
```

### Cleaning columns with dollar and comma sign

I modified colums with comma and dollar sign values and converted them to numeric format.

```{r}


###removing comma sign
Airbnb_data_final$price = gsub("\\,", "", Airbnb_data_final$price)
Airbnb_data_final$weekly_price = gsub("\\,", "", Airbnb_data_final$weekly_price)
Airbnb_data_final$monthly_price = gsub("\\,", "", Airbnb_data_final$monthly_price)
Airbnb_data_final$security_deposit = gsub("\\,", "", Airbnb_data_final$security_deposit)
Airbnb_data_final$cleaning_fee = gsub("\\,", "", Airbnb_data_final$cleaning_fee)
Airbnb_data_final$extra_people = gsub("\\,", "", Airbnb_data_final$extra_people)

###removing dollar sign
Airbnb_data_final$price = gsub("\\$", "", Airbnb_data_final$price)
Airbnb_data_final$weekly_price = gsub("\\$", "", Airbnb_data_final$weekly_price)
Airbnb_data_final$monthly_price = gsub("\\$", "", Airbnb_data_final$monthly_price)
Airbnb_data_final$security_deposit = gsub("\\$", "", Airbnb_data_final$security_deposit)
Airbnb_data_final$cleaning_fee = gsub("\\$", "", Airbnb_data_final$cleaning_fee)
Airbnb_data_final$extra_people = gsub("\\$", "", Airbnb_data_final$extra_people)


```

```{r}
#####converting back to alphanumeric
Airbnb_data_final$price = as.numeric(Airbnb_data_final$price)
Airbnb_data_final$weekly_price = as.numeric(Airbnb_data_final$weekly_price)
Airbnb_data_final$monthly_price = as.numeric(Airbnb_data_final$monthly_price)
Airbnb_data_final$security_deposit = as.numeric(Airbnb_data_final$security_deposit)
Airbnb_data_final$cleaning_fee = as.numeric(Airbnb_data_final$cleaning_fee)
Airbnb_data_final$extra_people = as.numeric(Airbnb_data_final$extra_people)
```

```{r}
head(Airbnb_data_final)

```


### Analyzing Longitude and Latitude Data 
I mapped the point data of the original Airbnb dataset, grouped by several variables, including neighbourhood_group_cleansed , neighborhood, room type, and price per night.

```{r}
Airbnb_data_final %>% ggplot(aes(x = longitude, y = latitude, color=neighbourhood_group_cleansed )) + geom_point(alpha = 0.4)
```

```{r Number_of_bedrooms}
# let us see the distribution of the bedrooms variable 
barplot(table(Airbnb_data$bedrooms),col = "orange",main = "Total number of the bedrooms variable",xlab = " Bedrooms Per House",ylab="Total Listing")
```

# Final Data Preprocessing
## Data Join of Airbnb and Zillow data sets
```{r}
final <- merge(Airbnb_data_final, zillow_nyc_final, by = "zipcode")
final <- subset(final,final$bedrooms == '2')
head(final)
```
## Checking columns with no data

```{r ,echo=TRUE,message=FALSE,warning=FALSE}
colSums(is.na(final))
```
## Missing Value Treatment Using Mice Package

```{r,echo=TRUE,message=FALSE,warning=FALSE}
#Converting Character Fields/Columns to Factors using 'mutate_if' function
na.model<-final%>%
  mutate_if(is.character, as.factor)%>%
  select(c(id, host_id, street, neighbourhood, neighbourhood_cleansed, neighbourhood_group_cleansed,   city,   zipcode,    market, smart_location, latitude,   longitude, accommodates, bathrooms, bedrooms, beds, price, weekly_price, monthly_price, security_deposit,  cleaning_fee, review_scores_location,review_scores_value,  guests_included, extra_people, availability_30, availability_60, availability_90, availability_365, cancellation_policy,predicted_price ))

set.seed(123)
miceMod <- mice(na.model, method='cart',m=1,maxit=1)  # perform mice imputation, based on CART/Decision Tree Algorithm. Number of iterations here is one
```

```{r,echo=TRUE,message=FALSE,warning=FALSE}
final_clean <- complete(miceMod) #New Data is generated with imputed values for missing observations

#Checking for missing values
anyNA(final_clean)
```
# Exploratory Data Analaysis

## Univariate Data Analysis
### Visualizing the number of properties listed by  room type

Manhattan has the most listings, followed by Brooklyn. Most of the listings are either “Entire home/apt” or “Private room”.

```{r}
ggplot(final, aes(neighbourhood_group_cleansed,fill = room_type)) + geom_bar() + labs(x = "Neighbourhood", y = "Number of Properties") + geom_text(stat='count', aes(label=..count..), vjust= -0.3)  + theme_classic()
```

```{r}
final %>% ggplot(aes(x = longitude, y = latitude, color= room_type)) + geom_point(alpha = 0.4)
```

### Visualizing Number of Property Listing by  Zipcode

Zipcodes 10003, 10011,10013,10014,10025,10036,11201,11215,11217, and 11231 have the highest number of properties listed.

```{r}
ggplot(final, aes(zipcode, fill = neighbourhood_group_cleansed)) + geom_bar() + labs(x = "Zipcode", y = "Properties Listed") + geom_text(stat='count', aes(label=..count..), vjust= -0.3) + theme(axis.text.x = element_text(angle = 90, hjust = 1))  + theme_bw() + theme(plot.background = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),panel.border = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1))
```

### Which Neigbourhood is the most Expensive

Manhattan and Brooklyn neighbourhoods are the most expensive.

```{r Spatial , echo=FALSE, message=FALSE, warning=FALSE}
#Which area is more expensive?
final_clean3= na.omit(final_clean)
final_clean3$predicted_price <- as.numeric(gsub(",", "", substring(final_clean3$predicted_price, 2)))
zipPrices <- final_clean3 %>% group_by(zipcode = zipcode ) %>% summarise(avg_predicted_price = mean(predicted_price, na.rm = TRUE))
colnames(zipPrices) <- c("region","value")
zipPrices$region <- as.character(zipPrices$region)
nyc_fips = c(36005, 36047, 36061, 36081, 36085)
g_price_location <- zip_choropleth(zipPrices,
county_zoom = nyc_fips,
title = "Average Price by Region",
legend = "Average Score") + ggtitle("Map showing the Most expensive Zipcodes in New York"
          ) +
  theme(plot.title = element_text(face = "bold")) +
     theme(plot.caption = element_text(color = "grey68"))+scale_color_gradient(low="#d3cbcb", high="#852eaa")+ scale_fill_brewer("Average Price",palette=4)
g_price_location
```


### Visualizing Density of Property Listing vs Price
The spread of prce per neighbourhood. 
+ Manhattan has the widest price spread.
+ Brooklyn has almost a perfect bell curve, which is a characterstic of normal real-world behaviour.
+ Staten Island and Queens have narrower distribution due to small sample size.

```{r,warning=FALSE}
g<-ggplot(final,aes(x=price, fill=neighbourhood_group_cleansed)) + geom_density(alpha = 0.3) + scale_x_continuous(limits = quantile(final$price, c(0, 0.99))) + labs(x = "Price/Night", y = "Density") + guides(fill = guide_legend(title = "Neighbourhood")) 
ggplotly(g)
```


## Bivariate Data Analysis

### Visualizing Property Availiability In Each Zipcode

```{r,echo=TRUE,message=FALSE,warning=FALSE}
final %>% group_by(neighbourhood_group_cleansed,zipcode) %>% summarise_all(funs(mean)) %>% ggplot(aes(x =zipcode,y= availability_365, fill = neighbourhood_group_cleansed )) + geom_bar(stat = "identity") + scale_y_continuous(labels = scales::comma) +  scale_colour_brewer(palette = "Pastel2") + labs( y = "Availability", x = "Zipcode") + theme_bw() + theme(plot.background = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),panel.border = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1)) + guides(fill = guide_legend(title = "Neighbourhood")) 
```


### Visualizing Property Predicted in Each Zipcode for February 2021

```{r,echo=TRUE,message=FALSE,warning=FALSE}
final %>% group_by(neighbourhood_group_cleansed,zipcode) %>% summarise_all(funs(mean)) %>% ggplot(aes(x =zipcode,y= predicted_price, fill = neighbourhood_group_cleansed )) + geom_bar(stat = "identity") + scale_y_continuous(labels = scales::comma) +  scale_colour_brewer(palette = "Pastel2") + labs( y = "Predicted Price", x = "Zipcode") + theme_bw() + theme(plot.background = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),panel.border = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1)) + guides(fill = guide_legend(title = "Neighbourhood"))
```


### Visualizing Price Variation for Property by Zipcode 

The  top 10 zipcodes which fetch highest price per night are: 10011,10013,10014,10022,10023,10028,10036,11201,11217, and 11231.



```{r visualizations1,fig.width=10,echo=TRUE,message=FALSE,warning=FALSE }


g<-ggplot(final, aes(x = zipcode,y = price, fill = neighbourhood_group_cleansed)) + geom_boxplot() + scale_y_continuous(limits = quantile(final$price, c(0, 0.99))) + labs(x = "Zipcode", y = "Price") + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +ggtitle("Price Variation for Property in NYC")+guides(fill = guide_legend(title = "Neighbourhood")) 
ggplotly(g)
```

### Visualizing Average Price for Property by Zipcode 

The average price decreases from 380 to 70.

```{r visualizations5,fig.width=10,echo=TRUE,message=FALSE,warning=FALSE}
final %>% select(zipcode,price) %>% filter(zipcode>0)%>% group_by(zipcode)%>% summarise(avg_price=mean(price,na.rm = T),count=n()) %>%arrange(desc(avg_price),count)%>%mutate_if(is.numeric,round,digits=0)%>% top_n(n = 25)%>% ggplot(.,mapping = aes(reorder(zipcode,-avg_price),avg_price))+geom_bar(stat = "identity",fill='steelblue')+ggtitle("Plot of average Airbnb price against zipcode")+xlab('zipcode')

```

### Visualizing Median Price for Property by Zipcode

Most prices are between $100 and $300. The median price is decreasing from $350 to $70.

```{r,echo=TRUE,message=FALSE,warning=FALSE}

final %>% select(zipcode,price) %>% filter(zipcode>0)%>% group_by(zipcode)%>% summarise(median_price=median(price,na.rm = T),count=n()) %>%arrange(desc(median_price),desc(count))%>%mutate_if(is.numeric,round,digits=0)%>% top_n(n = 25)%>% ggplot(.,mapping = aes(reorder(zipcode,-median_price),median_price))+geom_bar(stat = "identity",fill="orange")+ggtitle("Plot of median AirBnB price against zipcode")+xlab("zipcode")

```
From our observation above, the averages prices are higher than median prices because of outliers.



### Correlation Plot of Price, Reviews, Availability, and Predicted Price

```{r echo=TRUE,message=FALSE,warning=FALSE}
corCols <- c("availability_30","availability_60","availability_90","availability_365","review_scores_value","price","predicted_price")
plot_correlation(final_clean[corCols])
```


# Model Bulding and Evaluation

The model that we are going to cosnider while looking for a suitable propety to invest will be based on three approaches.

## Investing Approaches

 1. Optimal Revenue Model: In this approach, I am assuming that property will be sold after few years. Both revenue and real price, which is determine by the real estate appreciation cost of the property, is being considered. The discount factor has been assumed to be 0%. 
  2. Break Even Model: In this approach, we consider that property is going to be held indefinitely, and so the focus will only be on the revenues generated and the initial outlay. Discount factor will again be 0%. Our approach here is to calculate the number of years it will take for the property to break even.
  3. Mean Return Rate Model: In this approach, We are assuming that the expected return from a Zip will be the average of the revenue generated by all the listings in that Zip. We will then compare this average value of revenue with the property prices given to get mean annual return rate.

## Calculating Annual Returns and Annual Rate of Returns


```{r echo=TRUE,message=FALSE,warning=FALSE}
#Occupancy Rates based on Rating and Location conditions
#Generally good Neighbourhoods and well Rated accomodations will have better Occupancy Rates
final_clean<-final_clean%>%
  mutate(OccupancyRate=ifelse(review_scores_value >=9 &
                                (neighbourhood_group_cleansed=="Manhattan"|
                                   neighbourhood_group_cleansed=="Brooklyn"),0.75,
                              ifelse(review_scores_value >=9&
                                neighbourhood_group_cleansed=="Queens",0.70,ifelse((review_scores_value >=8  &review_scores_value<9)&
                                   (neighbourhood_group_cleansed=="Manhattan"|
                                      neighbourhood_group_cleansed=="Brooklyn"),0.65,0.55))))
```

```{r}
#75% Occupancy Rate
sum(final_clean$OccupancyRate==0.75)
```

```{r,echo=TRUE,message=FALSE,warning=FALSE}
final_clean<-final_clean%>%
  mutate(Annual_return=ifelse(is.na(monthly_price),365*price*OccupancyRate,
                                12*monthly_price*OccupancyRate))%>%
  mutate(Annual_Return_Rate=Annual_return/predicted_price)
```

```{r}
kable(as.data.frame(final_clean)) %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive")) %>% scroll_box(width = "100%", height = "350px")
```

```{r}
dim(final_clean)
```

## Visualizing Annual Return  Variation for Property in NYC

```{r visualizations7,fig.width=10,echo=TRUE,message=FALSE,warning=FALSE }
# boxplot to show variations in price within a zipcode
ggplot(data=final_clean,mapping = aes(zipcode,Annual_return/1000))+
geom_boxplot(outlier.colour = "Red",varwidth = TRUE)+ggtitle("Anuual Returns  Variation for Property in NYC")

```


## Visualizing Annual Return for Property in each ZipCode

From the two conclusions above and the third table, we can also infer that the number of properties in Brooklyn and Manhattan is pretty high compared to the others. Staten Island and Bronx have less than 1000 properties

```{r,echo=TRUE,message=FALSE,warning=FALSE}
ggplot(final_clean, aes(zipcode, fill = neighbourhood_group_cleansed)) + geom_bar() + labs(x = "Zipcode", y = "Annual_return") + geom_text(stat='count', aes(label=Annual_return), vjust= -0.3) + theme(axis.text.x = element_text(angle = 90, hjust = 1))  + theme_bw() + theme(plot.background = element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),panel.border = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1))

```

## Visualizing Annual Return for Property in each Neigbourhood

The Neighbourhood Queens has very high return on investments, between 10% and 20% for many zip codes. 11109 is the zip code with the highest return rate, 19%. 

```{r echo=TRUE,message=FALSE,warning=FALSE}

## usings plptly to create interactive plot 
theme_set(theme_classic())
g <- ggplot(data=final_clean, aes(Annual_Return_Rate*100))
g.g<-g + geom_density(aes(fill=factor(neighbourhood_group_cleansed)), alpha=0.8) + 
  labs(title="Density Plot", 
       subtitle="Annual Return Rate Grouped by Neighbourhood",
       caption="Source: Airbnb Data",
       x="Annual Return Rate(%)",
       y="Density",
       fill="Neighbourhood ")+scale_x_continuous(limits = c(0, 20))
p <- ggplotly(g.g)
p
```


## Mean Return Rate Model:Best zipcodes to Invest by Mean Return Rate

Mean property price in Manhattan and Brooklyn exceeds the mean property price in other neighborhoods. This is quite predictable, as these are busy cities, and there is heavy competition among real estate agents. Also the presence of corporate offices and buildings in that area boosts the property prices.

```{r echo=TRUE,message=FALSE,warning=FALSE}
final_clean4<-final_clean%>%
  filter(!is.na(zipcode))%>%
  select(zipcode,neighbourhood_group_cleansed,Annual_Return_Rate )%>%
  group_by(zipcode,neighbourhood_group_cleansed)%>%
  summarise(Mean_Return_Rate=mean(Annual_Return_Rate,na.rm=T))%>%
  arrange(Mean_Return_Rate)

final_clean4<-final_clean4%>%
  select(zipcode,neighbourhood_group_cleansed,Mean_Return_Rate)%>%
  head(25)

ggplot(data=final_clean4,aes(x=reorder(zipcode,-Mean_Return_Rate),y=Mean_Return_Rate*100,fill=neighbourhood_group_cleansed))+
  geom_bar(stat="identity")+ 
  #scale_fill_manual(values=c("red", "yellow","dark green","blue","grey"))+
  coord_flip()+ggtitle("Best Zipcodes to invest by Mean Return Rate")+xlab("Zipcode") +ylab("Mean Return Rate(%)") + labs(fill = "Neighbourhood Area")
```

## Break Even Model: Calculating The Break Even Period


```{r ,message=FALSE,warning=FALSE}
final_clean5<-final_clean%>%
  filter(!is.na(zipcode))%>%
  select(zipcode,neighbourhood_group_cleansed,Annual_return,predicted_price )%>%
  group_by(zipcode,neighbourhood_group_cleansed)%>%
  summarise(break_even=mean(predicted_price,na.rm=T)/mean(Annual_return,na.rm=T))%>%
  arrange(break_even)

final_clean5<-final_clean5%>%
  select(zipcode,neighbourhood_group_cleansed,break_even)%>%
  tail(25)


```

## Visulaizing the Break Even Period in Years 

The Break even period is calculated based on the mean predicted price of each zipcode. From the chart below,we can see that median amount of time taken by a zipcode to breakeven is between 30 and 50 years, not taking into account property appretion price.

```{r echo=TRUE,message=FALSE,warning=FALSE}
final_clean5 %>%
  arrange(break_even) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
  mutate(zipcodes=factor(zipcode)) %>%   # This trick update the factor levels
  ggplot( aes(x=zipcodes, y=break_even)) +
    geom_segment( aes(xend=zipcodes, yend=0)) +
    geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4) +
    coord_flip() +
    theme_bw() +
    ylab("Break Even in Years ")
    


```




# Conclusion

Using different approaches discussed in our model building segment, the best zipcodes to invest in are: 

1. Optimal Revenue Model: 11231 ,11217 ,11215, 10036,10025 ,10003 ,10011 ,10128

2. Break Even Model: 11434,10304,10309, 11234

3. Mean Return Rate Model: 11434, 11234, 11304


# Future Steps
+ Expand this analysis to multiple cities with compare patterns and trends between different cities. From the insights that have been derived, I would also like to build predictive models using different features from the dataset.

+ Merge this data with Covid-19 data to see how the pandemic would affect the demand and supply of airbnb rentals in the next few years in New York.

+ Introduce seasonality and weather data to understand trends in occupancy rates throughout the year and create a model to predict occupancy rate based on this insight.

+ Use NLP models to analyze the qualitative part of Airbnab data. We can account for the trends in reviews and get sentimental insights from word cloud that drive demand and occupancy rates.

# References
1. Exploratory Data Analysis of NYC Airbnb Listing Info and Demographics
https://xukeren.rbind.io/post/2019/12/31/exploratory-data-analysis-of-nyc-airbnb-listing-info-and-demographics/

2. Create a choropleth of US Zip Codes
https://arilamstein.com/documentation/choroplethrZip/reference/zip_choropleth.html#examples

3. Analysis of Airbnb Data in NYC 2019
 https://web.stanford.edu/~kjytay/courses/stats32-aut2019/Session%208/Airbnb_analysis.html 
